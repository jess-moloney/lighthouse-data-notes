{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Transformer example: Dataframe Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>FOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BAZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>QUUX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  text\n",
       "0   1   FOO\n",
       "1   2   BAR\n",
       "2   3   BAZ\n",
       "3   4  QUUX"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class DataframeFunctionTransformer():\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "# this function takes a dataframe as input and\n",
    "# returns a modified version thereof\n",
    "def process_dataframe(input_df):\n",
    "    input_df[\"text\"] = input_df[\"text\"].map(lambda t: t.upper())\n",
    "    return input_df\n",
    "\n",
    "# sample dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"id\":[1,2,3,4],\n",
    "    \"text\":[\"foo\",\"Bar\",\"BAz\",\"quux\"]\n",
    "})\n",
    "\n",
    "# this pipeline has a single step\n",
    "pipeline = Pipeline([\n",
    "    (\"uppercase\", DataframeFunctionTransformer(process_dataframe))\n",
    "])\n",
    "\n",
    "# apply the pipeline to the input dataframe\n",
    "pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Transformer example: To Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.sparse.csr_matrix([\n",
    "    [1.,0.,0.,0.,0.,0.],\n",
    "    [0.,1.,0.,0.,0.,0.],\n",
    "    [1.,0.,0.,0.,0.,0.],\n",
    "    [0.,0.,0.,0.,1.,0.],\n",
    "    [0.,0.,0.,1.,0.,0.],\n",
    "    [1.,0.,0.,0.,0.,0.],\n",
    "    [1.,1.,0.,0.,0.,0.],\n",
    "    [1.,1.,0.,0.,0.,0.],\n",
    "])\n",
    "\n",
    "target = np.asarray([1,1,1,0,0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ToDenseTransformer():\n",
    "\n",
    "    # here you define the operation it should perform\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    # just return self\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "# need to make matrices dense because PCA does not work with sparse vectors.\n",
    "pipeline = Pipeline([\n",
    "    ('to_dense',ToDenseTransformer()),\n",
    "    ('pca',PCA()),\n",
    "    ('clf',DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "pipeline.fit(data,target)\n",
    "pipeline.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Transformer example: Select Dataframe Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charlie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>david</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edward</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name\n",
       "0    alice\n",
       "1      bob\n",
       "2  charlie\n",
       "3    david\n",
       "4   edward"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class SelectColumnsTransformer():\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        cpy_df = X[self.columns].copy()\n",
    "        return cpy_df\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'name':['alice','bob','charlie','david','edward'],\n",
    "    'age':[24,32,np.nan,38,20]\n",
    "})\n",
    "\n",
    "# create a pipeline with a single transformer\n",
    "pipe = Pipeline([\n",
    "    ('selector', SelectColumnsTransformer([\"name\"]))\n",
    "])\n",
    "\n",
    "pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColumnTransformer Example: Missing imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.0, 'alice'],\n",
       "       [32.0, 'bob'],\n",
       "       [28.5, 'charlie'],\n",
       "       [38.0, 'david'],\n",
       "       [20.0, 'edward']], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'name':['alice','bob','charlie','david','edward'],\n",
    "    'age':[24,32,np.nan,38,20]\n",
    "})\n",
    "\n",
    "transformer_step = ColumnTransformer([\n",
    "        ('impute_mean', SimpleImputer(strategy='mean'), ['age'])\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('select', transformer_step)\n",
    "])\n",
    "\n",
    "# fit as you would a normal transformer\n",
    "pipe.fit(df)\n",
    "\n",
    "# transform the input\n",
    "pipe.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FunctionTransformer with Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mrslp\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('rslp')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mstemmers/rslp/step0.pt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\User/nltk_data'\n    - 'c:\\\\Program Files\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [10], line 30\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([stemmer\u001b[39m.\u001b[39mstem(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m input_str\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)])\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m input_series\u001b[39m.\u001b[39mapply(stem)\n\u001b[0;32m     27\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline([\n\u001b[0;32m     28\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mstemmer\u001b[39m\u001b[39m'\u001b[39m, FunctionTransformer(\n\u001b[0;32m     29\u001b[0m         func\u001b[39m=\u001b[39mstem_str,                        \u001b[39m# function to be used\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m         kw_args\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mstemmer\u001b[39m\u001b[39m'\u001b[39m: RSLPStemmer()})), \u001b[39m# parameters to the function\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mvect\u001b[39m\u001b[39m'\u001b[39m, TfidfVectorizer()),\n\u001b[0;32m     32\u001b[0m     (\u001b[39m'\u001b[39m\u001b[39mclf\u001b[39m\u001b[39m'\u001b[39m, LogisticRegression())\n\u001b[0;32m     33\u001b[0m ])\n\u001b[0;32m     35\u001b[0m \u001b[39m# now use it like you would any pipeline\u001b[39;00m\n\u001b[0;32m     36\u001b[0m pipeline\u001b[39m.\u001b[39mfit(df[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m],df[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\stem\\rslp.py:56\u001b[0m, in \u001b[0;36mRSLPStemmer.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     54\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_rule(\u001b[39m\"\u001b[39;49m\u001b[39mstep0.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_rule(\u001b[39m\"\u001b[39m\u001b[39mstep1.pt\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_rule(\u001b[39m\"\u001b[39m\u001b[39mstep2.pt\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\stem\\rslp.py:65\u001b[0m, in \u001b[0;36mRSLPStemmer.read_rule\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_rule\u001b[39m(\u001b[39mself\u001b[39m, filename):\n\u001b[1;32m---> 65\u001b[0m     rules \u001b[39m=\u001b[39m load(\u001b[39m\"\u001b[39;49m\u001b[39mnltk:stemmers/rslp/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m filename, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mraw\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     66\u001b[0m     lines \u001b[39m=\u001b[39m rules\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     68\u001b[0m     lines \u001b[39m=\u001b[39m [line \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines \u001b[39mif\u001b[39;00m line \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# remove blank lines\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<<Loading \u001b[39m\u001b[39m{\u001b[39;00mresource_url\u001b[39m}\u001b[39;00m\u001b[39m>>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[39m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[39m=\u001b[39m _open(resource_url)\n\u001b[0;32m    752\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[39m=\u001b[39m opened_resource\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[39m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnltk\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, path \u001b[39m+\u001b[39;49m [\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[39melif\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[39m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mopen()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mrslp\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('rslp')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mstemmers/rslp/step0.pt\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\User/nltk_data'\n    - 'c:\\\\Program Files\\\\Python39\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python39\\\\share\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python39\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# dummy dataframe\n",
    "df = pd.DataFrame({\n",
    "    'text':[\n",
    "        'Lorem ipsum dolor sit amet, consectetur adipiscing elit.',\n",
    "        'Sed accumsan congue enim non pretium.',\n",
    "        'In hac habitasse platea dictumst.',\n",
    "        'Sed tincidunt ipsum nec urna vulputate luctus.'\n",
    "    ],\n",
    "    'target':[0, 1, 0, 1]\n",
    "})\n",
    "\n",
    "# function takes a dataframe row and a stemmer\n",
    "def stem_str(input_series, stemmer):\n",
    "\n",
    "    def stem(input_str):\n",
    "        return \" \".join([stemmer.stem(t) for t in input_str.split(\" \")]).strip()\n",
    "\n",
    "    return input_series.apply(stem)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('stemmer', FunctionTransformer(\n",
    "        func=stem_str,                        # function to be used\n",
    "        kw_args={'stemmer': RSLPStemmer()})), # parameters to the function\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "# now use it like you would any pipeline\n",
    "pipeline.fit(df[\"text\"],df[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with Preprocessing and Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical_preprocessing&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;ohe&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [&#x27;favorite_color&#x27;]),\n",
       "                                                 (&#x27;numerical_preprocessing&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputation&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  [&#x27;age&#x27;])])),\n",
       "                (&#x27;clf&#x27;, DecisionTreeClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;categorical_preprocessing&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;ohe&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [&#x27;favorite_color&#x27;]),\n",
       "                                                 (&#x27;numerical_preprocessing&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputation&#x27;,\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  [&#x27;age&#x27;])])),\n",
       "                (&#x27;clf&#x27;, DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;categorical_preprocessing&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;ohe&#x27;, OneHotEncoder())]),\n",
       "                                 [&#x27;favorite_color&#x27;]),\n",
       "                                (&#x27;numerical_preprocessing&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputation&#x27;,\n",
       "                                                  SimpleImputer())]),\n",
       "                                 [&#x27;age&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical_preprocessing</label><div class=\"sk-toggleable__content\"><pre>[&#x27;favorite_color&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_preprocessing</label><div class=\"sk-toggleable__content\"><pre>[&#x27;age&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(transformers=[('categorical_preprocessing',\n",
       "                                                  Pipeline(steps=[('ohe',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['favorite_color']),\n",
       "                                                 ('numerical_preprocessing',\n",
       "                                                  Pipeline(steps=[('imputation',\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  ['age'])])),\n",
       "                ('clf', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# this is the input dataframe\n",
    "df = pd.DataFrame({\n",
    "    'favorite_color':['blue','green','red','green','blue'],\n",
    "    'age': [10,15,10,np.nan,10],\n",
    "    'target':[1,0,1,0,1]\n",
    "})\n",
    "\n",
    "# define individual transformers in a pipeline\n",
    "categorical_preprocessing = Pipeline([('ohe', OneHotEncoder())])\n",
    "numerical_preprocessing = Pipeline([('imputation', SimpleImputer())])\n",
    "\n",
    "# define which transformer applies to which columns\n",
    "preprocess = ColumnTransformer([\n",
    "    ('categorical_preprocessing', categorical_preprocessing, ['favorite_color']),\n",
    "    ('numerical_preprocessing', numerical_preprocessing, ['age'])\n",
    "])\n",
    "\n",
    "# create the final pipeline with preprocessing steps and \n",
    "# the final classifier step\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocess),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# now fit the pipeline using the whole dataframe\n",
    "df_features = df[['favorite_color','age']]\n",
    "df_target = df['target']\n",
    "\n",
    "# call fit on the dataframes\n",
    "pipeline.fit(df_features, df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
